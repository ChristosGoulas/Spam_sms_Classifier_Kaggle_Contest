{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data \n",
      "    Label                                               Text\n",
      "0   True  YOU HAVE WON! As a valued Vodafone customer ou...\n",
      "1  False  I‘ve got some salt, you can rub it in my open ...\n",
      "2   True  Xmas & New Years Eve tickets are now on sale f...\n",
      "3   True  3 FREE TAROT TEXTS! Find out about your love l...\n",
      "4  False                    Like  &lt;#&gt; , same question\n",
      "Test data \n",
      "    Id                                               Text\n",
      "0   1  Designation is software developer and may be s...\n",
      "1   2     How do you guys go to see movies on your side.\n",
      "2   3  Urgh, coach hot, smells of chip fat! Thanks ag...\n",
      "3   4                             R u in this continent?\n",
      "4   5                    She's fine. Sends her greetings\n",
      "Length of Training data \n",
      " 4343\n",
      "Length of Test data \n",
      " 1114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Label\n",
       "False    3761\n",
       "True      582\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('training_data.txt', sep=\"\\t\", names=['Label','Text'])\n",
    "test_data = pd.read_csv('test_data.txt', sep=\"\\t\", names=['Id','Text'])\n",
    "print(\"Training data \\n\",data.head())\n",
    "print(\"Test data \\n\",test_data.head())\n",
    "print(\"Length of Training data \\n\", len(data))\n",
    "print(\"Length of Test data \\n\", len(test_data))\n",
    "data.groupby('Label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: Label, dtype: int32\n",
      "0    YOU HAVE WON! As a valued Vodafone customer ou...\n",
      "1    I‘ve got some salt, you can rub it in my open ...\n",
      "2    Xmas & New Years Eve tickets are now on sale f...\n",
      "3    3 FREE TAROT TEXTS! Find out about your love l...\n",
      "4                      Like  &lt;#&gt; , same question\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data.Label = data.Label.astype(int)\n",
    "data_y = data['Label']\n",
    "data_x = data['Text']\n",
    "test = test_data['Text']\n",
    "print(data_y.head())\n",
    "print(data_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "   (0, 1712)\t1\n",
      "  (0, 6094)\t1\n",
      "  (1, 3177)\t1\n",
      "  (1, 4468)\t1\n",
      "  (2, 1741)\t1\n",
      "  (2, 2560)\t1\n",
      "  (2, 2692)\t1\n",
      "  (2, 3393)\t1\n",
      "  (2, 6586)\t1\n",
      "  (2, 6602)\t1\n",
      "  (2, 7333)\t1\n",
      "  (4, 2764)\t1\n",
      "  (4, 3134)\t1\n",
      "  (4, 5832)\t1\n",
      "  (5, 933)\t1\n",
      "  (5, 1314)\t1\n",
      "  (5, 1457)\t1\n",
      "  (5, 1949)\t1\n",
      "  (5, 2125)\t1\n",
      "  (5, 2812)\t1\n",
      "  (5, 3080)\t1\n",
      "  (5, 4623)\t1\n",
      "  (5, 6399)\t1\n",
      "  (5, 7120)\t1\n",
      "  (5, 7289)\t1\n",
      "  :\t:\n",
      "  (1108, 3490)\t1\n",
      "  (1108, 3745)\t1\n",
      "  (1108, 5252)\t1\n",
      "  (1108, 7089)\t1\n",
      "  (1108, 7353)\t1\n",
      "  (1109, 778)\t1\n",
      "  (1109, 2239)\t1\n",
      "  (1109, 3242)\t1\n",
      "  (1109, 4323)\t1\n",
      "  (1109, 5993)\t1\n",
      "  (1110, 3359)\t1\n",
      "  (1110, 3884)\t1\n",
      "  (1110, 4073)\t1\n",
      "  (1110, 6338)\t1\n",
      "  (1110, 7117)\t1\n",
      "  (1111, 4142)\t1\n",
      "  (1111, 6210)\t1\n",
      "  (1111, 6875)\t1\n",
      "  (1112, 866)\t1\n",
      "  (1112, 3308)\t1\n",
      "  (1112, 3891)\t1\n",
      "  (1112, 4288)\t1\n",
      "  (1113, 4274)\t1\n",
      "  (1113, 7190)\t1\n",
      "  (1113, 7432)\t1\n",
      "x_traincv: \n",
      "   (0, 7319)\t1\n",
      "  (0, 7009)\t1\n",
      "  (0, 7077)\t1\n",
      "  (0, 2070)\t1\n",
      "  (0, 1886)\t1\n",
      "  (0, 5033)\t1\n",
      "  (0, 7270)\t1\n",
      "  (0, 300)\t1\n",
      "  (0, 5249)\t1\n",
      "  (0, 1835)\t1\n",
      "  (0, 2439)\t1\n",
      "  (0, 3746)\t1\n",
      "  (0, 197)\t1\n",
      "  (1, 7023)\t1\n",
      "  (1, 3093)\t1\n",
      "  (1, 5711)\t1\n",
      "  (1, 5663)\t1\n",
      "  (1, 4804)\t1\n",
      "  (1, 7357)\t1\n",
      "  (1, 3976)\t1\n",
      "  (2, 7394)\t1\n",
      "  (2, 4613)\t1\n",
      "  (2, 7424)\t1\n",
      "  (2, 2573)\t1\n",
      "  (2, 6672)\t1\n",
      "  :\t:\n",
      "  (4339, 3716)\t1\n",
      "  (4339, 3183)\t2\n",
      "  (4340, 4446)\t1\n",
      "  (4340, 5055)\t1\n",
      "  (4340, 6387)\t1\n",
      "  (4341, 6963)\t2\n",
      "  (4341, 5829)\t1\n",
      "  (4341, 5650)\t1\n",
      "  (4341, 5168)\t1\n",
      "  (4341, 1622)\t2\n",
      "  (4341, 687)\t1\n",
      "  (4341, 302)\t1\n",
      "  (4341, 2063)\t1\n",
      "  (4341, 535)\t1\n",
      "  (4341, 6389)\t1\n",
      "  (4341, 397)\t1\n",
      "  (4341, 7100)\t1\n",
      "  (4341, 1176)\t1\n",
      "  (4341, 138)\t1\n",
      "  (4341, 3309)\t1\n",
      "  (4341, 4264)\t1\n",
      "  (4341, 1643)\t1\n",
      "  (4341, 4293)\t1\n",
      "  (4342, 4290)\t1\n",
      "  (4342, 2114)\t1\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df = 1 , stop_words = 'english')\n",
    "x_traincv = cv.fit_transform(data_x)\n",
    "test = cv.transform(test)\n",
    "y_train = data_y.astype('int')\n",
    "print(\"Test: \\n\", test)\n",
    "print(\"x_traincv: \\n\", x_traincv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "151\n",
      "[  16   36   47   52   53   60   63   64   66   67   77   80   81  103\n",
      "  104  105  111  129  155  156  175  179  187  191  197  199  211  226\n",
      "  243  247  248  264  271  275  278  280  293  312  319  324  334  348\n",
      "  356  366  367  372  375  376  400  404  406  414  420  425  427  459\n",
      "  467  468  471  498  512  513  514  523  536  537  540  550  558  560\n",
      "  561  565  573  589  597  601  605  612  613  619  620  627  639  672\n",
      "  673  686  687  698  702  714  730  736  738  740  748  755  758  759\n",
      "  782  786  787  800  806  808  809  810  812  819  830  838  840  844\n",
      "  845  850  854  863  871  879  893  897  902  917  924  926  934  944\n",
      "  949  956  972  978  983  986  990  998 1001 1004 1021 1028 1031 1035\n",
      " 1044 1049 1050 1054 1059 1066 1080 1089 1098 1099 1100]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_traincv,y_train)\n",
    "test.toarray()\n",
    "predictions = clf.predict(test)\n",
    "print(predictions.dtype)\n",
    "len(predictions)\n",
    "print(np.sum(predictions, axis=0))\n",
    "print(\"The possition in the array where we found spams... +1 and it is the row in the test data txt\")\n",
    "print(np.where(predictions != 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1-score Score per class\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fed4cea82124>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nF1-score Score per class\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nAverage F1 Score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpredictions_matrix\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m   1058\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1059\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m   1180\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1182\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1183\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1413\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1415\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                          str(average_options))\n\u001b[0;32m   1238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m     71\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;31m# Invalid inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m     if y.ndim > 2 or (y.dtype == object and len(y) and\n\u001b[0m\u001b[0;32m    270\u001b[0m                       not isinstance(y.flat[0], str)):\n\u001b[0;32m    271\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'unknown'\u001b[0m  \u001b[1;31m# [[[1, 2]]] or [obj_1] and not [\"label_1\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "print(\"\\nF1-score Score per class\")\n",
    "print(metrics.f1_score(test , predictions , average=None))\n",
    "print(\"\\nAverage F1 Score\")\n",
    "print(metrics.f1_score(test , predictions_matrix , average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
